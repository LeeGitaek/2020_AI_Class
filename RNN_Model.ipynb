{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfZDR/KKiLf9f3XAoBvMFa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeGitaek/2020_AI_Class/blob/master/RNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwbhrJCjWsCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "from torch.autograd import Variable\n",
        "import numpy as np "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRvwJj_ZAPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden = 50\n",
        "learning_rate = 0.01\n",
        "epochs = 2000 \n",
        "\n",
        "string = \"hello pytorch.how long can a rnn cell remember?\"# show us your limit!\"\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
        "char_list = [i for i in chars]\n",
        "char_len = len(char_list)\n",
        "n_letters = len(char_list)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQVA0mJC1is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape=len(char_list),dtype=int)\n",
        "    end   = np.zeros(shape=len(char_list),dtype=int)\n",
        "    start[-2] = 1\n",
        "    end[-1] = 1\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape=char_len,dtype=int)\n",
        "        zero[idx] = 1\n",
        "        start = np.vstack([start,zero])\n",
        "    output = np.vstack([start,end])\n",
        "    return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXZ41-jyEKdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrFVyd51FWHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN with 1 hidden layer\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size):\n",
        "        super(RNN,self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self,input,hidden):\n",
        "        hidden = self.act_fn(self.i2h(input)+self.h2h(hidden))\n",
        "        output = self.i2o(hidden)\n",
        "        return output,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(1,self.hidden_size))\n",
        "\n",
        "\n",
        "rnn = RNN(n_letters,n_hidden,n_letters)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYzRgMzSHgKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaMiT_0aHuiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bbe073b-5bcc-49b8-a6ed-a5c836f8bbce"
      },
      "source": [
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    rnn.zero_grad()\n",
        "    total_loss = 0\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "        input = Variable(one_hot[j:j+1,:])\n",
        "        output, hidden = rnn.forward(input, hidden)\n",
        "        target = Variable(one_hot[j+1])\n",
        "        loss = loss_func(output.view(-1),target.view(-1))\n",
        "        total_loss += loss\n",
        "        input = output\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch {:.4f}  / cost = {:.6f}'.format(epoch,total_loss))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0.0000  / cost = 0.000211\n",
            "epoch 10.0000  / cost = 0.000187\n",
            "epoch 20.0000  / cost = 0.000075\n",
            "epoch 30.0000  / cost = 0.000067\n",
            "epoch 40.0000  / cost = 0.000160\n",
            "epoch 50.0000  / cost = 0.000249\n",
            "epoch 60.0000  / cost = 0.000372\n",
            "epoch 70.0000  / cost = 0.000117\n",
            "epoch 80.0000  / cost = 0.000173\n",
            "epoch 90.0000  / cost = 0.000116\n",
            "epoch 100.0000  / cost = 0.000062\n",
            "epoch 110.0000  / cost = 0.000096\n",
            "epoch 120.0000  / cost = 0.000153\n",
            "epoch 130.0000  / cost = 0.000096\n",
            "epoch 140.0000  / cost = 0.000119\n",
            "epoch 150.0000  / cost = 0.000020\n",
            "epoch 160.0000  / cost = 0.000060\n",
            "epoch 170.0000  / cost = 0.000248\n",
            "epoch 180.0000  / cost = 0.000117\n",
            "epoch 190.0000  / cost = 0.000614\n",
            "epoch 200.0000  / cost = 0.000480\n",
            "epoch 210.0000  / cost = 0.000342\n",
            "epoch 220.0000  / cost = 0.000158\n",
            "epoch 230.0000  / cost = 0.000060\n",
            "epoch 240.0000  / cost = 0.000027\n",
            "epoch 250.0000  / cost = 0.000018\n",
            "epoch 260.0000  / cost = 0.000067\n",
            "epoch 270.0000  / cost = 0.000071\n",
            "epoch 280.0000  / cost = 0.000123\n",
            "epoch 290.0000  / cost = 0.000086\n",
            "epoch 300.0000  / cost = 0.000089\n",
            "epoch 310.0000  / cost = 0.000169\n",
            "epoch 320.0000  / cost = 0.000248\n",
            "epoch 330.0000  / cost = 0.000102\n",
            "epoch 340.0000  / cost = 0.000061\n",
            "epoch 350.0000  / cost = 0.000080\n",
            "epoch 360.0000  / cost = 0.000098\n",
            "epoch 370.0000  / cost = 0.000054\n",
            "epoch 380.0000  / cost = 0.000044\n",
            "epoch 390.0000  / cost = 0.000189\n",
            "epoch 400.0000  / cost = 0.000216\n",
            "epoch 410.0000  / cost = 0.000321\n",
            "epoch 420.0000  / cost = 0.000280\n",
            "epoch 430.0000  / cost = 0.000202\n",
            "epoch 440.0000  / cost = 0.000154\n",
            "epoch 450.0000  / cost = 0.000071\n",
            "epoch 460.0000  / cost = 0.000208\n",
            "epoch 470.0000  / cost = 0.000094\n",
            "epoch 480.0000  / cost = 0.000078\n",
            "epoch 490.0000  / cost = 0.000017\n",
            "epoch 500.0000  / cost = 0.000019\n",
            "epoch 510.0000  / cost = 0.000063\n",
            "epoch 520.0000  / cost = 0.000326\n",
            "epoch 530.0000  / cost = 0.000100\n",
            "epoch 540.0000  / cost = 0.000175\n",
            "epoch 550.0000  / cost = 0.000308\n",
            "epoch 560.0000  / cost = 0.000319\n",
            "epoch 570.0000  / cost = 0.000557\n",
            "epoch 580.0000  / cost = 0.000217\n",
            "epoch 590.0000  / cost = 0.000098\n",
            "epoch 600.0000  / cost = 0.000033\n",
            "epoch 610.0000  / cost = 0.000018\n",
            "epoch 620.0000  / cost = 0.000026\n",
            "epoch 630.0000  / cost = 0.000112\n",
            "epoch 640.0000  / cost = 0.000087\n",
            "epoch 650.0000  / cost = 0.000108\n",
            "epoch 660.0000  / cost = 0.000325\n",
            "epoch 670.0000  / cost = 0.000235\n",
            "epoch 680.0000  / cost = 0.000193\n",
            "epoch 690.0000  / cost = 0.000078\n",
            "epoch 700.0000  / cost = 0.000076\n",
            "epoch 710.0000  / cost = 0.000047\n",
            "epoch 720.0000  / cost = 0.000018\n",
            "epoch 730.0000  / cost = 0.000025\n",
            "epoch 740.0000  / cost = 0.000253\n",
            "epoch 750.0000  / cost = 0.000091\n",
            "epoch 760.0000  / cost = 0.000200\n",
            "epoch 770.0000  / cost = 0.000279\n",
            "epoch 780.0000  / cost = 0.000625\n",
            "epoch 790.0000  / cost = 0.000394\n",
            "epoch 800.0000  / cost = 0.000101\n",
            "epoch 810.0000  / cost = 0.000039\n",
            "epoch 820.0000  / cost = 0.000019\n",
            "epoch 830.0000  / cost = 0.000043\n",
            "epoch 840.0000  / cost = 0.000431\n",
            "epoch 850.0000  / cost = 0.000100\n",
            "epoch 860.0000  / cost = 0.000041\n",
            "epoch 870.0000  / cost = 0.000114\n",
            "epoch 880.0000  / cost = 0.000481\n",
            "epoch 890.0000  / cost = 0.000183\n",
            "epoch 900.0000  / cost = 0.000147\n",
            "epoch 910.0000  / cost = 0.000103\n",
            "epoch 920.0000  / cost = 0.000084\n",
            "epoch 930.0000  / cost = 0.000052\n",
            "epoch 940.0000  / cost = 0.000013\n",
            "epoch 950.0000  / cost = 0.000009\n",
            "epoch 960.0000  / cost = 0.000020\n",
            "epoch 970.0000  / cost = 0.000162\n",
            "epoch 980.0000  / cost = 0.000114\n",
            "epoch 990.0000  / cost = 0.000229\n",
            "epoch 1000.0000  / cost = 0.000598\n",
            "epoch 1010.0000  / cost = 0.000363\n",
            "epoch 1020.0000  / cost = 0.000205\n",
            "epoch 1030.0000  / cost = 0.000107\n",
            "epoch 1040.0000  / cost = 0.000095\n",
            "epoch 1050.0000  / cost = 0.000025\n",
            "epoch 1060.0000  / cost = 0.000136\n",
            "epoch 1070.0000  / cost = 0.000092\n",
            "epoch 1080.0000  / cost = 0.000167\n",
            "epoch 1090.0000  / cost = 0.000264\n",
            "epoch 1100.0000  / cost = 0.000062\n",
            "epoch 1110.0000  / cost = 0.000040\n",
            "epoch 1120.0000  / cost = 0.000034\n",
            "epoch 1130.0000  / cost = 0.000141\n",
            "epoch 1140.0000  / cost = 0.000291\n",
            "epoch 1150.0000  / cost = 0.000430\n",
            "epoch 1160.0000  / cost = 0.000118\n",
            "epoch 1170.0000  / cost = 0.000735\n",
            "epoch 1180.0000  / cost = 0.000317\n",
            "epoch 1190.0000  / cost = 0.000395\n",
            "epoch 1200.0000  / cost = 0.000237\n",
            "epoch 1210.0000  / cost = 0.000369\n",
            "epoch 1220.0000  / cost = 0.000124\n",
            "epoch 1230.0000  / cost = 0.000051\n",
            "epoch 1240.0000  / cost = 0.000016\n",
            "epoch 1250.0000  / cost = 0.000005\n",
            "epoch 1260.0000  / cost = 0.000004\n",
            "epoch 1270.0000  / cost = 0.000015\n",
            "epoch 1280.0000  / cost = 0.000149\n",
            "epoch 1290.0000  / cost = 0.000116\n",
            "epoch 1300.0000  / cost = 0.000074\n",
            "epoch 1310.0000  / cost = 0.000072\n",
            "epoch 1320.0000  / cost = 0.000111\n",
            "epoch 1330.0000  / cost = 0.000117\n",
            "epoch 1340.0000  / cost = 0.000252\n",
            "epoch 1350.0000  / cost = 0.000075\n",
            "epoch 1360.0000  / cost = 0.000032\n",
            "epoch 1370.0000  / cost = 0.000015\n",
            "epoch 1380.0000  / cost = 0.000022\n",
            "epoch 1390.0000  / cost = 0.000336\n",
            "epoch 1400.0000  / cost = 0.000207\n",
            "epoch 1410.0000  / cost = 0.000645\n",
            "epoch 1420.0000  / cost = 0.000316\n",
            "epoch 1430.0000  / cost = 0.000362\n",
            "epoch 1440.0000  / cost = 0.000193\n",
            "epoch 1450.0000  / cost = 0.000097\n",
            "epoch 1460.0000  / cost = 0.000046\n",
            "epoch 1470.0000  / cost = 0.000015\n",
            "epoch 1480.0000  / cost = 0.000006\n",
            "epoch 1490.0000  / cost = 0.000009\n",
            "epoch 1500.0000  / cost = 0.000061\n",
            "epoch 1510.0000  / cost = 0.000311\n",
            "epoch 1520.0000  / cost = 0.000180\n",
            "epoch 1530.0000  / cost = 0.000163\n",
            "epoch 1540.0000  / cost = 0.000041\n",
            "epoch 1550.0000  / cost = 0.000217\n",
            "epoch 1560.0000  / cost = 0.000151\n",
            "epoch 1570.0000  / cost = 0.000197\n",
            "epoch 1580.0000  / cost = 0.000127\n",
            "epoch 1590.0000  / cost = 0.000171\n",
            "epoch 1600.0000  / cost = 0.000198\n",
            "epoch 1610.0000  / cost = 0.000047\n",
            "epoch 1620.0000  / cost = 0.000057\n",
            "epoch 1630.0000  / cost = 0.000295\n",
            "epoch 1640.0000  / cost = 0.000105\n",
            "epoch 1650.0000  / cost = 0.000237\n",
            "epoch 1660.0000  / cost = 0.000059\n",
            "epoch 1670.0000  / cost = 0.000075\n",
            "epoch 1680.0000  / cost = 0.000145\n",
            "epoch 1690.0000  / cost = 0.000147\n",
            "epoch 1700.0000  / cost = 0.000199\n",
            "epoch 1710.0000  / cost = 0.000162\n",
            "epoch 1720.0000  / cost = 0.000172\n",
            "epoch 1730.0000  / cost = 0.000166\n",
            "epoch 1740.0000  / cost = 0.000104\n",
            "epoch 1750.0000  / cost = 0.000178\n",
            "epoch 1760.0000  / cost = 0.000270\n",
            "epoch 1770.0000  / cost = 0.000300\n",
            "epoch 1780.0000  / cost = 0.000295\n",
            "epoch 1790.0000  / cost = 0.000218\n",
            "epoch 1800.0000  / cost = 0.000110\n",
            "epoch 1810.0000  / cost = 0.000074\n",
            "epoch 1820.0000  / cost = 0.000084\n",
            "epoch 1830.0000  / cost = 0.000120\n",
            "epoch 1840.0000  / cost = 0.000039\n",
            "epoch 1850.0000  / cost = 0.000036\n",
            "epoch 1860.0000  / cost = 0.000054\n",
            "epoch 1870.0000  / cost = 0.000149\n",
            "epoch 1880.0000  / cost = 0.000389\n",
            "epoch 1890.0000  / cost = 0.000236\n",
            "epoch 1900.0000  / cost = 0.000394\n",
            "epoch 1910.0000  / cost = 0.000301\n",
            "epoch 1920.0000  / cost = 0.000657\n",
            "epoch 1930.0000  / cost = 0.000322\n",
            "epoch 1940.0000  / cost = 0.000175\n",
            "epoch 1950.0000  / cost = 0.000095\n",
            "epoch 1960.0000  / cost = 0.000100\n",
            "epoch 1970.0000  / cost = 0.000045\n",
            "epoch 1980.0000  / cost = 0.000029\n",
            "epoch 1990.0000  / cost = 0.000047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCe_N3D0IB3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30d24e26-35b9-4d1a-c817-82c8651c8a53"
      },
      "source": [
        "hidden = rnn.init_hidden()\n",
        "input = Variable(one_hot[0:1,:])\n",
        "\n",
        "for i in range(len(string)):\n",
        "    output, hidden = rnn.forward(input, hidden)\n",
        "    print(onehot_to_word(output.data),end=\"\")\n",
        "    input = output"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello pytorch.how long can a rnn cell remember?"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}